{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6d91617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From g:\\Softwares\\Miniconda\\envs\\convo_capsule\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Libraries imported successfully!\n",
      "TensorFlow version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, T5Tokenizer, TFT5ForConditionalGeneration\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e8e759c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample transcript loaded.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Our Sample Data (Input)\n",
    "# (Please re-run this cell to ensure we're using this text)\n",
    "\n",
    "MEETING_TRANSCRIPT = \"\"\"\n",
    "Tom: Okay everyone, let's kick off. The main goal today is to finalize the new marketing slogan for the Q4 launch. Sarah, what does your team have?\n",
    "\n",
    "Sarah: Thanks, Tom. We've narrowed it down to three options. \"Innovation for Tomorrow,\" \"Your Future, Our Passion,\" and \"Simply Better.\" The data suggests \"Simply Better\" is resonating most with our test groups.\n",
    "\n",
    "Alex: I agree. It's clean and direct. \"Innovation for Tomorrow\" is too generic.\n",
    "\n",
    "Tom: Good point, Alex. Let's go with \"Simply Better.\" Sarah, can you please get the final design assets to the web team?\n",
    "\n",
    "Sarah: Will do. I'll have them sent over by end-of-day Friday.\n",
    "\n",
    "Alex: I also have an action item. I will coordinate with the legal team to get the trademark paperwork started for \"Simply Better.\" I should have an update on that by our next meeting.\n",
    "\n",
    "Tom: Perfect. That's all for today. Great work, team.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Sample transcript loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55cb0f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading summarization model... (This may take a moment on first run)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Falling back to torch.float32 because loading with the original dtype failed on the target device.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ✅ MEETING SUMMARY ---\n",
      "\"Simply Better\" is resonating most with our test groups,\" says Tom. \"Innovation for Tomorrow\" is too generic. Sarah, can you please get the final design assets to the web team?\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading summarization model... (This may take a moment on first run)\")\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "summary_output = summarizer(\n",
    "    MEETING_TRANSCRIPT, \n",
    "    max_length=90, \n",
    "    min_length=30, \n",
    "    do_sample=False\n",
    ")\n",
    "\n",
    "print(\"\\n--- ✅ MEETING SUMMARY ---\")\n",
    "print(summary_output[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae126793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading FLAN-T5 model with a new prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From g:\\Softwares\\Miniconda\\envs\\convo_capsule\\lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
      "g:\\Softwares\\Miniconda\\envs\\convo_capsule\\lib\\site-packages\\tf_keras\\src\\initializers\\initializers.py:121: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFT5ForConditionalGeneration: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight']\n",
      "- This IS expected if you are initializing TFT5ForConditionalGeneration from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFT5ForConditionalGeneration from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ✅ ACTION ITEMS ---\n",
      "Tom, Sarah, Alex, Alex and Tom will finalize the new slogan for the Q4 launch. Sarah will have the final design assets sent over by end-of-day Friday. Alex will coordinate with the legal team to get the trademark paperwork started for \"Simply Better.\"\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Task 2 - Extract Action Items (Using a Simple Prompt)\n",
    "\n",
    "print(\"\\nLoading FLAN-T5 model with a new prompt...\")\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model = TFT5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\", from_pt=True)\n",
    "\n",
    "# --- THIS IS THE NEW, SIMPLIFIED PROMPT ---\n",
    "# We are removing the complex \"Format as...\" instructions\n",
    "# and just giving a clear task.\n",
    "prompt = f\"\"\"\n",
    "What are the assigned tasks for this transcript.\n",
    "\n",
    "Transcript:\n",
    "{MEETING_TRANSCRIPT}\n",
    "\n",
    "Assigned Tasks:\n",
    "\"\"\"\n",
    "\n",
    "# Now we run the model\n",
    "inputs = tokenizer.encode(prompt, return_tensors=\"tf\", max_length=1024, truncation=True)\n",
    "\n",
    "outputs = model.generate(\n",
    "    inputs, \n",
    "    max_length=200, \n",
    "    num_beams=4,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# Decode the output\n",
    "action_items_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"\\n--- ✅ ACTION ITEMS ---\")\n",
    "print(action_items_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf3128bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading audio file: A1-044-LYRA-WHERE-DO-YOU-GO-IN-THE-MORNING.mp3...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6256ca741b16455b97c18088c8b9abe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating audio split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading audio file. Make sure 'A1-044-LYRA-WHERE-DO-YOU-GO-IN-THE-MORNING.mp3' is in the same directory.\n",
      "Error: An error occurred while generating the dataset\n"
     ]
    },
    {
     "ename": "DatasetGenerationError",
     "evalue": "An error occurred while generating the dataset",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mg:\\Softwares\\Miniconda\\envs\\convo_capsule\\lib\\site-packages\\datasets\\features\\audio.py:103\u001b[0m, in \u001b[0;36mAudio.encode_example\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchcodec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mencoders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AudioEncoder  \u001b[38;5;66;03m# needed to write audio files\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchcodec'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mg:\\Softwares\\Miniconda\\envs\\convo_capsule\\lib\\site-packages\\datasets\\builder.py:1588\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._prepare_split_single\u001b[1;34m(self, gen_kwargs, fpath, file_format, max_shard_size, split_info, check_duplicate_keys, job_id)\u001b[0m\n\u001b[0;32m   1579\u001b[0m     writer \u001b[38;5;241m=\u001b[39m writer_class(\n\u001b[0;32m   1580\u001b[0m         features\u001b[38;5;241m=\u001b[39mwriter\u001b[38;5;241m.\u001b[39m_features,\n\u001b[0;32m   1581\u001b[0m         path\u001b[38;5;241m=\u001b[39mfpath\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSSSSS\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshard_id\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m05d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJJJJJ\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob_id\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m05d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1586\u001b[0m         embed_local_files\u001b[38;5;241m=\u001b[39membed_local_files,\n\u001b[0;32m   1587\u001b[0m     )\n\u001b[1;32m-> 1588\u001b[0m example \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m record\n\u001b[0;32m   1589\u001b[0m writer\u001b[38;5;241m.\u001b[39mwrite(example, key)\n",
      "File \u001b[1;32mg:\\Softwares\\Miniconda\\envs\\convo_capsule\\lib\\site-packages\\datasets\\features\\features.py:2048\u001b[0m, in \u001b[0;36mFeatures.encode_example\u001b[1;34m(self, example)\u001b[0m\n\u001b[0;32m   2047\u001b[0m example \u001b[38;5;241m=\u001b[39m cast_to_python_objects(example)\n\u001b[1;32m-> 2048\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mencode_nested_example\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mg:\\Softwares\\Miniconda\\envs\\convo_capsule\\lib\\site-packages\\datasets\\features\\features.py:1343\u001b[0m, in \u001b[0;36mencode_nested_example\u001b[1;34m(schema, obj, level)\u001b[0m\n\u001b[0;32m   1341\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot None but expected a dictionary instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1342\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m-> 1343\u001b[0m         {k: encode_nested_example(schema[k], obj\u001b[38;5;241m.\u001b[39mget(k), level\u001b[38;5;241m=\u001b[39mlevel \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m schema}\n\u001b[0;32m   1344\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1345\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1346\u001b[0m     )\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, (LargeList, List)):\n",
      "File \u001b[1;32mg:\\Softwares\\Miniconda\\envs\\convo_capsule\\lib\\site-packages\\datasets\\features\\features.py:1343\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1341\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot None but expected a dictionary instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1342\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m-> 1343\u001b[0m         {k: \u001b[43mencode_nested_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m schema}\n\u001b[0;32m   1344\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1345\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1346\u001b[0m     )\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, (LargeList, List)):\n",
      "File \u001b[1;32mg:\\Softwares\\Miniconda\\envs\\convo_capsule\\lib\\site-packages\\datasets\\features\\features.py:1366\u001b[0m, in \u001b[0;36mencode_nested_example\u001b[1;34m(schema, obj, level)\u001b[0m\n\u001b[0;32m   1365\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(schema, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencode_example\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;66;03m# Other object should be directly convertible to a native Arrow type (like Translation and Translation)\u001b[39;00m\n",
      "File \u001b[1;32mg:\\Softwares\\Miniconda\\envs\\convo_capsule\\lib\\site-packages\\datasets\\features\\audio.py:105\u001b[0m, in \u001b[0;36mAudio.encode_example\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo support encoding audio data, please install \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorchcodec\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: To support encoding audio data, please install 'torchcodec'.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDatasetGenerationError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 18\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# --- 2. LOAD AND RESAMPLE THE AUDIO ---\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# This is the most reliable way to load audio.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Whisper *requires* the audio to be at 16,000Hz (16kHz).\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# This 'Audio' tool will automatically load AND resample it for us.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 18\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudiofolder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mAUDIO_FILE_PATH\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# Get the first (and only) audio file's data\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     input_audio \u001b[38;5;241m=\u001b[39m ds[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mg:\\Softwares\\Miniconda\\envs\\convo_capsule\\lib\\site-packages\\datasets\\load.py:1417\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[0;32m   1414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m builder_instance\u001b[38;5;241m.\u001b[39mas_streaming_dataset(split\u001b[38;5;241m=\u001b[39msplit)\n\u001b[0;32m   1416\u001b[0m \u001b[38;5;66;03m# Download and prepare data\u001b[39;00m\n\u001b[1;32m-> 1417\u001b[0m \u001b[43mbuilder_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1419\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1423\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1425\u001b[0m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[0;32m   1426\u001b[0m keep_in_memory \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1427\u001b[0m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size)\n\u001b[0;32m   1428\u001b[0m )\n",
      "File \u001b[1;32mg:\\Softwares\\Miniconda\\envs\\convo_capsule\\lib\\site-packages\\datasets\\builder.py:897\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[1;34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[0;32m    895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    896\u001b[0m     prepare_split_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_proc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_proc\n\u001b[1;32m--> 897\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_and_prepare(\n\u001b[0;32m    898\u001b[0m     dl_manager\u001b[38;5;241m=\u001b[39mdl_manager,\n\u001b[0;32m    899\u001b[0m     verification_mode\u001b[38;5;241m=\u001b[39mverification_mode,\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprepare_split_kwargs,\n\u001b[0;32m    901\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdownload_and_prepare_kwargs,\n\u001b[0;32m    902\u001b[0m )\n\u001b[0;32m    903\u001b[0m \u001b[38;5;66;03m# Sync info\u001b[39;00m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(split\u001b[38;5;241m.\u001b[39mnum_bytes \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39msplits\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[1;32mg:\\Softwares\\Miniconda\\envs\\convo_capsule\\lib\\site-packages\\datasets\\builder.py:1612\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, verification_mode, **prepare_splits_kwargs)\u001b[0m\n\u001b[0;32m   1611\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_download_and_prepare\u001b[39m(\u001b[38;5;28mself\u001b[39m, dl_manager, verification_mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprepare_splits_kwargs):\n\u001b[1;32m-> 1612\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_download_and_prepare(\n\u001b[0;32m   1613\u001b[0m         dl_manager,\n\u001b[0;32m   1614\u001b[0m         verification_mode,\n\u001b[0;32m   1615\u001b[0m         check_duplicate_keys\u001b[38;5;241m=\u001b[39mverification_mode \u001b[38;5;241m==\u001b[39m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS\n\u001b[0;32m   1616\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m verification_mode \u001b[38;5;241m==\u001b[39m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS,\n\u001b[0;32m   1617\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprepare_splits_kwargs,\n\u001b[0;32m   1618\u001b[0m     )\n",
      "File \u001b[1;32mg:\\Softwares\\Miniconda\\envs\\convo_capsule\\lib\\site-packages\\datasets\\builder.py:973\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[0;32m    969\u001b[0m split_dict\u001b[38;5;241m.\u001b[39madd(split_generator\u001b[38;5;241m.\u001b[39msplit_info)\n\u001b[0;32m    971\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    972\u001b[0m     \u001b[38;5;66;03m# Prepare split will record examples associated to the split\u001b[39;00m\n\u001b[1;32m--> 973\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_split(split_generator, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprepare_split_kwargs)\n\u001b[0;32m    974\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    975\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[0;32m    976\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find data file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_download_instructions \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    978\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOriginal error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    979\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[0;32m    980\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mg:\\Softwares\\Miniconda\\envs\\convo_capsule\\lib\\site-packages\\datasets\\builder.py:1450\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._prepare_split\u001b[1;34m(self, split_generator, check_duplicate_keys, file_format, num_proc, max_shard_size)\u001b[0m\n\u001b[0;32m   1448\u001b[0m job_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1449\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pbar:\n\u001b[1;32m-> 1450\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m job_id, done, content \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_split_single(\n\u001b[0;32m   1451\u001b[0m         gen_kwargs\u001b[38;5;241m=\u001b[39mgen_kwargs, job_id\u001b[38;5;241m=\u001b[39mjob_id, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_prepare_split_args\n\u001b[0;32m   1452\u001b[0m     ):\n\u001b[0;32m   1453\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[0;32m   1454\u001b[0m             result \u001b[38;5;241m=\u001b[39m content\n",
      "File \u001b[1;32mg:\\Softwares\\Miniconda\\envs\\convo_capsule\\lib\\site-packages\\datasets\\builder.py:1607\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._prepare_split_single\u001b[1;34m(self, gen_kwargs, fpath, file_format, max_shard_size, split_info, check_duplicate_keys, job_id)\u001b[0m\n\u001b[0;32m   1605\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, SchemaInferenceError) \u001b[38;5;129;01mand\u001b[39;00m e\u001b[38;5;241m.\u001b[39m__context__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1606\u001b[0m         e \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39m__context__\n\u001b[1;32m-> 1607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetGenerationError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while generating the dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1609\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m job_id, \u001b[38;5;28;01mTrue\u001b[39;00m, (total_num_examples, total_num_bytes, writer\u001b[38;5;241m.\u001b[39m_features, num_shards, shard_lengths)\n",
      "\u001b[1;31mDatasetGenerationError\u001b[0m: An error occurred while generating the dataset"
     ]
    }
   ],
   "source": [
    "# Cell 6: Full Pipeline (Audio -> Text -> Summary)\n",
    "\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset, Audio # We use this to load audio\n",
    "import librosa # We don't use it directly, but 'transformers' needs it\n",
    "\n",
    "# --- 1. DEFINE YOUR AUDIO FILE ---\n",
    "# Change this to the name of your audio file\n",
    "AUDIO_FILE_PATH = \"A1-044-LYRA-WHERE-DO-YOU-GO-IN-THE-MORNING.mp3\" \n",
    "\n",
    "print(f\"Loading audio file: {AUDIO_FILE_PATH}...\")\n",
    "\n",
    "# --- 2. LOAD AND RESAMPLE THE AUDIO ---\n",
    "# This is the most reliable way to load audio.\n",
    "# Whisper *requires* the audio to be at 16,000Hz (16kHz).\n",
    "# This 'Audio' tool will automatically load AND resample it for us.\n",
    "try:\n",
    "    ds = load_dataset(\"audiofolder\", data_files={\"audio\": AUDIO_FILE_PATH}, split=\"audio\")\n",
    "    # Get the first (and only) audio file's data\n",
    "    input_audio = ds[0][\"audio\"]\n",
    "    print(\"Audio loaded and resampled successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading audio file. Make sure '{AUDIO_FILE_PATH}' is in the same directory.\")\n",
    "    print(f\"Error: {e}\")\n",
    "    # Stop here if the file didn't load\n",
    "    raise\n",
    "\n",
    "# --- 3. TASK 1: AUDIO-TO-TEXT (ASR) ---\n",
    "print(\"\\nLoading Whisper ASR model... (This will download the model)\")\n",
    "\n",
    "# We use the \"automatic-speech-recognition\" pipeline.\n",
    "# 'openai/whisper-base' is a great, fast model to start with.\n",
    "# The pipeline will auto-detect your TensorFlow backend.\n",
    "asr_pipeline = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=\"openai/whisper-base\"\n",
    ")\n",
    "\n",
    "# Run the audio through the ASR pipeline\n",
    "# We pass the raw audio data (input_audio['array'])\n",
    "transcribed_output = asr_pipeline(input_audio['array'])\n",
    "transcribed_text = transcribed_output[\"text\"]\n",
    "\n",
    "print(\"\\n--- ✅ TRANSCRIBED TEXT ---\")\n",
    "print(transcribed_text)\n",
    "\n",
    "\n",
    "# --- 4. TASK 2: TEXT-TO-SUMMARY ---\n",
    "print(\"\\nLoading summarization model...\")\n",
    "\n",
    "# This is our pipeline from Cell 3.\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Run the *transcribed text* through the summarizer\n",
    "summary_output = summarizer(\n",
    "    transcribed_text, \n",
    "    max_length=150, # Made max_length a bit longer for potentially long text\n",
    "    min_length=30, \n",
    "    do_sample=False\n",
    ")\n",
    "\n",
    "print(\"\\n--- ✅ FINAL SUMMARY (FROM AUDIO) ---\")\n",
    "print(summary_output[0]['summary_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "convo_capsule",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
