{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6d91617",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, T5Tokenizer, TFT5ForConditionalGeneration\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8e759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Our Sample Data (Input)\n",
    "# (Please re-run this cell to ensure we're using this text)\n",
    "\n",
    "MEETING_TRANSCRIPT = \"\"\"\n",
    "Tom: Okay everyone, let's kick off. The main goal today is to finalize the new marketing slogan for the Q4 launch. Sarah, what does your team have?\n",
    "\n",
    "Sarah: Thanks, Tom. We've narrowed it down to three options. \"Innovation for Tomorrow,\" \"Your Future, Our Passion,\" and \"Simply Better.\" The data suggests \"Simply Better\" is resonating most with our test groups.\n",
    "\n",
    "Alex: I agree. It's clean and direct. \"Innovation for Tomorrow\" is too generic.\n",
    "\n",
    "Tom: Good point, Alex. Let's go with \"Simply Better.\" Sarah, can you please get the final design assets to the web team?\n",
    "\n",
    "Sarah: Will do. I'll have them sent over by end-of-day Friday.\n",
    "\n",
    "Alex: I also have an action item. I will coordinate with the legal team to get the trademark paperwork started for \"Simply Better.\" I should have an update on that by our next meeting.\n",
    "\n",
    "Tom: Perfect. That's all for today. Great work, team.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Sample transcript loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cb0f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading summarization model... (This may take a moment on first run)\")\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "summary_output = summarizer(\n",
    "    MEETING_TRANSCRIPT, \n",
    "    max_length=90, \n",
    "    min_length=30, \n",
    "    do_sample=False\n",
    ")\n",
    "\n",
    "print(\"\\n--- ✅ MEETING SUMMARY ---\")\n",
    "print(summary_output[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae126793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Task 2 - Extract Action Items (Using a Simple Prompt)\n",
    "\n",
    "print(\"\\nLoading FLAN-T5 model with a new prompt...\")\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model = TFT5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\", from_pt=True)\n",
    "\n",
    "# --- THIS IS THE NEW, SIMPLIFIED PROMPT ---\n",
    "# We are removing the complex \"Format as...\" instructions\n",
    "# and just giving a clear task.\n",
    "prompt = f\"\"\"\n",
    "What are the assigned tasks for this transcript.\n",
    "\n",
    "Transcript:\n",
    "{MEETING_TRANSCRIPT}\n",
    "\n",
    "Assigned Tasks:\n",
    "\"\"\"\n",
    "\n",
    "# Now we run the model\n",
    "inputs = tokenizer.encode(prompt, return_tensors=\"tf\", max_length=1024, truncation=True)\n",
    "\n",
    "outputs = model.generate(\n",
    "    inputs, \n",
    "    max_length=200, \n",
    "    num_beams=4,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# Decode the output\n",
    "action_items_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"\\n--- ✅ ACTION ITEMS ---\")\n",
    "print(action_items_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3128bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Full Pipeline (Audio -> Text -> Summary) - Corrected for Long Audio\n",
    "\n",
    "from transformers import pipeline\n",
    "import librosa\n",
    "import tensorflow as tf \n",
    "\n",
    "AUDIO_FILE_PATH = \"A1-044-LYRA-WHERE-DO-YOU-GO-IN-THE-MORNING.mp3\" \n",
    "\n",
    "print(f\"Loading audio file: {AUDIO_FILE_PATH}...\")\n",
    "\n",
    "try:\n",
    "    input_audio_array, sample_rate = librosa.load(AUDIO_FILE_PATH, sr=16000)\n",
    "    print(\"Audio loaded and resampled to 16kHz successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading audio file. Make sure '{AUDIO_FILE_PATH}' is in the same directory.\")\n",
    "    print(f\"Error: {e}\")\n",
    "    raise\n",
    "\n",
    "# --- 3. TASK 1: AUDIO-TO-TEXT (ASR) ---\n",
    "print(\"\\nLoading Whisper ASR model...\")\n",
    "\n",
    "asr_pipeline = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=\"openai/whisper-base\"\n",
    ")\n",
    "\n",
    "print(\"Transcribing audio... (This may take a moment)\")\n",
    "\n",
    "# --- THIS IS THE FIX ---\n",
    "# We add 'chunk_length_s=30' to tell the pipeline to\n",
    "# automatically chunk the long audio.\n",
    "transcribed_output = asr_pipeline(input_audio_array, chunk_length_s=30)\n",
    "transcribed_text = transcribed_output[\"text\"]\n",
    "\n",
    "print(\"\\n--- ✅ TRANSCRIBED TEXT ---\")\n",
    "print(transcribed_text)\n",
    "\n",
    "\n",
    "# --- 4. TASK 2: TEXT-TO-SUMMARY ---\n",
    "print(\"\\nLoading summarization model...\")\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "summary_output = summarizer(\n",
    "    transcribed_text, \n",
    "    max_length=150,\n",
    "    min_length=30, \n",
    "    do_sample=False\n",
    ")\n",
    "\n",
    "print(\"\\n--- ✅ FINAL SUMMARY (FROM AUDIO) ---\")\n",
    "print(summary_output[0]['summary_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Convo_capsule",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
